{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa34a35-72f3-45d6-a212-edd86e7ca945",
   "metadata": {},
   "source": [
    "# VL03 - Text Representation\n",
    "In this seminar we will explore how to transform raw text data into numerical vectors that machine learning models can understand. We will focus on two foundational methods: Bag-of-Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe29cc2-e3a8-4ef0-b3e9-438efa8a622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6838d4-378c-4325-8234-dd80304e43f2",
   "metadata": {},
   "source": [
    "## 1. Loading the dataset\n",
    "\n",
    "Later we will use:\n",
    "https://www.kaggle.com/datasets/saadmakhdoom/ecommerce-faq-chatbot-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c97ee-95a3-48b7-955c-f7a75ed24c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = [\n",
    "    \"How do I reset my password, and are passwords case-sensitive?\", \n",
    "    \"How to update my email address, and is updating necessary for security?\", \n",
    "    \"I can't log in to my account. What are the common login issues?\", \n",
    "    \"How do I change my payment method for the upcoming billing cycle?\", \n",
    "    \"I want to cancel my active monthly subscription and stop future payments.\",\n",
    "    \"What is the return policy if a product is still under warranty?\",\n",
    "    \"How to change my username if I am currently logging in with my email?\",\n",
    "    \"How do I enable two-factor authentication for my account?\",\n",
    "    \"How to update the billing address associated with my credit card.\",\n",
    "    \"How do I account for changes in my order? Can I cancel it?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7883d980-f01b-4967-a856-762f78f82b2b",
   "metadata": {},
   "source": [
    "## 2. Bag of Words\n",
    "The Bag-of-Words model is the simplest form of text representation. It represents a text (like a sentence or document) as the multiset of its words, disregarding grammar and even word order, but keeping track of word frequency.\n",
    "\n",
    "### 2.1 Building the vocabulary\n",
    "The first step in BoW is to fit the corpus with `.fit_transform()` to create a vocabularyâ€”a list of all unique words found across the entire corpus. `CountVectorizer` which performs tokenization (breaking text into words) and optionally, basic preprocessing (like lowercasing).\n",
    "\n",
    "With after processing the corpus with `.fit_transform()` we \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b940b-ef35-46c5-a086-11014badf47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer comes with some text-processing features, such as stop_words, case folding\n",
    "vectorizer_bow = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the vectorizer to the corpus to build the vocabulary \n",
    "# (vectorizer_bow.vocabulary_ contains a dictionary mapping token -> column index)\n",
    "bow_matrix = vectorizer_bow.fit_transform(faqs)\n",
    "\n",
    "# Get the unique words (features) that form the vocabulary\n",
    "vocabulary = vectorizer_bow.get_feature_names_out()\n",
    "\n",
    "def print_vocabulary(vocabulary):\n",
    "    print(f\"Total vocabulary size: {len(vocabulary)}\\n\")\n",
    "    print(\"Vocabulary (unique tokens):\")\n",
    "    print(vocabulary)\n",
    "\n",
    "print_vocabulary(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c0f98-4484-4cbb-9663-d936eb8e4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bow.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d29d7-4b5d-484c-8fab-9d976f634264",
   "metadata": {},
   "source": [
    "### 2.2 Our own text-processing pipeline\n",
    "We can define our own pre-processing pipeine by providing a tokenizer argument `CountVectorizer(tokenizer=my_tokenizer)`, which returns the list of (pre-processed) tokens for the input corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44116ffc-73a6-4c87-a229-08cc33c19677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the small English language model for spaCy\n",
    "# We will use this model to perform advanced pre-processing (like lemmatization)\n",
    "# Note: You may need to run `python -m spacy download en_core_web_sm` once in your environment\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "except OSError:\n",
    "    print(\"Warning: spaCy model 'en_core_web_sm' not found. Please run 'python -m spacy download en_core_web_sm'\")\n",
    "    # Fallback to a simpler model creation if the standard one fails\n",
    "    nlp = spacy.blank(\"en\")\n",
    "\n",
    "\n",
    "# --- NEW CUSTOM TOKENIZER FUNCTION ---\n",
    "def spacy_tokenizer(document):\n",
    "    \"\"\"\n",
    "    Custom tokenizer using spaCy for advanced pre-processing.\n",
    "    It performs tokenization, lemmatization, and removes stop words/punctuation.\n",
    "    This aligns the process with the manual steps students learned previously.\n",
    "    \"\"\"\n",
    "    # 1. Process the document with spaCy\n",
    "    doc = nlp(document)\n",
    "    \n",
    "    # 2. Extract tokens, perform lemmatization, and filter:\n",
    "    #    - .lemma_: the base form of the word (e.g., 'updates' -> 'update')\n",
    "    #    - .is_stop: skip common stop words (if the model is loaded)\n",
    "    #    - .is_punct: skip punctuation\n",
    "    #    - .is_alpha: keep only tokens that are purely alphabetic\n",
    "    tokens = [\n",
    "        token.lemma_.lower() \n",
    "        for token in doc \n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "    ]\n",
    "    return tokens\n",
    "# --- END NEW CUSTOM TOKENIZER FUNCTION ---\n",
    "\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "# 1. We now pass our custom spacy_tokenizer function to the 'tokenizer' argument.\n",
    "# 2. We set 'stop_words' to None because spaCy_tokenizer handles stop words internally.\n",
    "# 3. We set 'token_pattern' to None because the custom tokenizer handles token extraction.\n",
    "vectorizer_bow = CountVectorizer(tokenizer=spacy_tokenizer, \n",
    "                                 stop_words=None, \n",
    "                                 token_pattern=None)\n",
    "\n",
    "# Fit the vectorizer to the corpus to build the vocabulary\n",
    "# The vectorizer now calls spacy_tokenizer(faq) for every document in `faqs`\n",
    "bow_matrix = vectorizer_bow.fit_transform(faqs)\n",
    "\n",
    "# Get the unique words (features) that form the vocabulary\n",
    "vocabulary = vectorizer_bow.get_feature_names_out()\n",
    "\n",
    "\n",
    "print_vocabulary(vocabulary)\n",
    "    \n",
    "print(\"\\n--- Note the effect of Lemmatization! ---\")\n",
    "print(\"Words like 'resets' or 'updating' would now appear as 'reset' or 'update' if they were present in the corpus.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72592c81-f61e-48e8-99e7-db97db9e0347",
   "metadata": {},
   "source": [
    "### 2.3 Examining the BoW vector\n",
    "Each document is now represented as a vector where the length equals the size of the vocabulary. The value at each position in the vector is the count of how often that corresponding word appears in the document.\n",
    "\n",
    "Let's look at the full matrix and then inspect the vector for a Document by changing `doc_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df040f87-5434-4f35-ad81-38c00c64a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a DataFrame for readability\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vocabulary)\n",
    "bow_df.index = [f\"D{i+1}\" for i in range(len(faqs))]\n",
    "\n",
    "print(\"--- Full BoW Matrix (Counts) ---\")\n",
    "print(bow_df.T) # the transpose to display documents as columns\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Inspect a specific document\n",
    "doc_index = 0\n",
    "doc_vector = bow_df.iloc[doc_index]\n",
    "\n",
    "print(f\"--- BoW Vector for Document {doc_index}---\")\n",
    "print(f\"Document: {faqs[doc_index]}\\n\")\n",
    "\n",
    "# Show only the words that appear in this document (count > 0)\n",
    "present_words = doc_vector[doc_vector > 0].sort_values(ascending=False)\n",
    "print(present_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34405c4d-0dcc-4865-8bbd-59c9a993d9ff",
   "metadata": {},
   "source": [
    "### 2.4 Document similarity\n",
    "A key use of BoW is to find documents that are semantically similar. We can calculate the Cosine Similarity between their vectors. Cosine similarity measures the cosine of the angle between two non-zero vectors. A value close to 1 indicates high similarity.\n",
    "\n",
    "Note: To use the `cosine_similarity()` function, we added  `from sklearn.metrics.pairwise import cosine_similarity` at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf44a83-d894-4816-9503-325ff23c0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_u_idx = 1\n",
    "vector_v_idx = 6\n",
    "#vector_v_idx = 2\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_u_v = cosine_similarity(bow_matrix[vector_u_idx], bow_matrix[vector_v_idx])\n",
    "\n",
    "print(f\"D1: {faqs[vector_u_idx]}\")\n",
    "print(f\"D5: {faqs[vector_v_idx]}\")\n",
    "print(f\"\\nCosine Similarity (BoW): {similarity_u_v[0][0]:.4f}\")\n",
    "\n",
    "similarity_u_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6a7aa-a52c-45d5-984c-f94366e31f47",
   "metadata": {},
   "source": [
    "### 2.5 Matching an incoming query\n",
    "To match an incoming user query to the most relevant FAQ, we transform the query into a BoW vector using the same fitted vectorizer and calculate its similarity against all document vectors.\n",
    "\n",
    "In the code below, notice that we take `vectorizer_bow` which was fitted with the FAQ corpus in Section 2.1 (`vectorizer_bow.fit_transform(faqs)`), so as to apply the exact same vocabulary, tokenization, and pipeline to the incoming query. Here, however, we apply the `.transform()` function. \n",
    "\n",
    "Let's try two queries:\n",
    "- Q1. How do I change my password\n",
    "- Q2. How do I change my account's password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6d6d4-30f5-4e02-802d-5d3e135c78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = [\"How do I change my account's password\",]\n",
    "query = [\"How do I change my password\",]\n",
    "\n",
    "# Transform the query using the *fitted* CountVectorizer\n",
    "query_vector = vectorizer_bow.transform(query)\n",
    "\n",
    "# Calculate similarity between the query and ALL document vectors\n",
    "similarities = cosine_similarity(query_vector, bow_matrix)\n",
    "\n",
    "# Create a DataFrame for the results, correctly pairing the scores and the FAQ text.\n",
    "# 1. Start with the index and similarity scores.\n",
    "# 2. Add the corresponding FAQ text as a new column.\n",
    "results_bow = pd.DataFrame({\n",
    "    'similarity_score' : similarities[0], # the index '0' is the index of the query document\n",
    "    'faq_text': faqs\n",
    "}, index = [f\"{i}\" for i in range(len(faqs))] )\n",
    "\n",
    "results_bow = results_bow.sort_values(by=[\"similarity_score\"], ascending=False)\n",
    "\n",
    "\n",
    "print(\"--- BoW Matching Results ---\")\n",
    "print(f\"Query: {query[0]}\")\n",
    "print(\"-\" * 30)\n",
    "print(results_bow.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e3a1c-08bb-4cf2-a750-4427e248b7b3",
   "metadata": {},
   "source": [
    "### 2.6 Reflect on the BoW limitations\n",
    "Can you inspect the results for each query and explain the results? When is the similarity-based matching failing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec55c0-5ef2-481c-8cad-ee8e36cfc252",
   "metadata": {},
   "source": [
    "## 3. TF-IDF Representations\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) addresses the \"equal importance\" problem of BoW. It assigns a higher score to words that are relevant (frequent within a document) but distinctive (rare across the entire corpus).\n",
    "\n",
    "### 3.1 Inspecting TF and IDF components\n",
    "`TfidfVectorizer` calculates two components:\n",
    "- Term Frequency (TF): How often a term appears in a document (similar to BoW, but often normalized).\n",
    "- Inverse Document Frequency (IDF): A measure of how important or rare a term is across the whole corpus. Rare words get a higher IDF score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c647e24-2eb2-472b-ad65-2f787b4103a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer with the custom tokenizer\n",
    "vectorizer_tfidf = TfidfVectorizer(tokenizer=spacy_tokenizer, \n",
    "                                   stop_words=None,\n",
    "                                   token_pattern=None)\n",
    "\n",
    "# Fit and transform the corpus\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(faqs)\n",
    "\n",
    "# Get the feature names and the IDF scores\n",
    "vocabulary_tfidf = vectorizer_tfidf.get_feature_names_out()\n",
    "idf_scores = vectorizer_tfidf.idf_\n",
    "\n",
    "# Create a DataFrame to view words and their IDF scores\n",
    "idf_df = pd.DataFrame({\n",
    "    'word': vocabulary_tfidf,\n",
    "    'idf_score': idf_scores\n",
    "}).sort_values(by='idf_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"--- Words Sorted by IDF Score (Rarity) ---\")\n",
    "print(\"High IDF -> Rare words (More valuable for distinction)\")\n",
    "print(\"Low IDF -> Frequent words (Less valuable for distinction)\\n\")\n",
    "\n",
    "# Show the 5 rarest and 5 most frequent words\n",
    "print(idf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8033a52d-67a0-43e1-8ddb-fb7655d2012c",
   "metadata": {},
   "source": [
    "### 3.2 Query matching with TF-IDF\n",
    "Let's re-run the same query matching exercise with the TF-IDF vectors. We expect the results to be more accurate because the unique, differentiating words in the query will be weighted more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab99dd-95e3-4864-98d8-ab5706521fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = from the bow code cell..\n",
    "\n",
    "# Transform the query using the *fitted* TfidfVectorizer\n",
    "query_vector_tfidf = vectorizer_tfidf.transform(query)\n",
    "\n",
    "# Calculate similarity between the query and ALL document vectors\n",
    "similarities_tfidf = cosine_similarity(query_vector_tfidf, tfidf_matrix)\n",
    "\n",
    "# Create a dataframe to display the results nicely\n",
    "results_tfidf = pd.DataFrame({\n",
    "    'similarity_score' : similarities_tfidf[0], # the index '0' is the index of the query document\n",
    "    'faq_text': faqs\n",
    "}, index = [f\"{i}\" for i in range(len(faqs))] )\n",
    "\n",
    "results_tfidf = results_tfidf.sort_values(by=[\"similarity_score\"], ascending=False)\n",
    "\n",
    "\n",
    "print(\"--- BoW Matching Results ---\")\n",
    "print(f\"Query: {query[0]}\")\n",
    "print(\"-\" * 30)\n",
    "print(results_bow.head(3))\n",
    "\n",
    "print(\"--- TF-IDF Matching Results ---\")\n",
    "print(f\"Query: {query[0]}\")\n",
    "print(\"-\" * 30)\n",
    "print(results_tfidf.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cf381-a9f6-4951-93df-320ddbd743a8",
   "metadata": {},
   "source": [
    "### 3.3 Reflect on the differences between BoW and TF-IDF representations\n",
    "- How do they compare in terms of how they address Q1 and Q2?\n",
    "- What are the lingering limitations in TF-IDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6424707-e1ad-4973-8c84-01587803ae71",
   "metadata": {},
   "source": [
    "## 4. Demo on a real FAQ dataset\n",
    "\n",
    "Execute the following on your terminal to download the dataset:\n",
    "\n",
    "``\n",
    "mkdir -p data && \\\n",
    "curl -L -o data/kaggle_faq_dataset.zip 'https://www.kaggle.com/api/v1/datasets/download/saadmakhdoom/ecommerce-faq-chatbot-dataset' && \\\n",
    "unzip -o data/kaggle_faq_dataset.zip -d data\n",
    "``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a414b1b-077d-4027-8e77-a01902f4108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script performs a benchmark comparison of Bag-of-Words (BoW) and TF-IDF\n",
    "# on a real-world FAQ retrieval task using a locally available JSON dataset.\n",
    "import json\n",
    "import os\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# --- 2. TEXT PRE-PROCESSING  ---\n",
    "\n",
    "def spacy_tokenizer(text, do_normalise = True):\n",
    "    \"\"\"\n",
    "    Custom tokenizer function using spaCy for high-quality preprocessing:\n",
    "    1. Tokenization\n",
    "    2. Lowercasing\n",
    "    3. Lemmatization (reducing words to root form, e.g., 'updates' -> 'update')\n",
    "    4. Removing punctuation, extra whitespace, and stop words\n",
    "    \"\"\"\n",
    "    # Process the text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    if (do_normalise):\n",
    "    # Extract clean tokens: lemma_, is_punct=False, is_space=False, is_stop=False\n",
    "        tokens = [\n",
    "            token.lemma_\n",
    "            for token in doc\n",
    "            if not token.is_punct and not token.is_space and not token.is_stop\n",
    "        ]\n",
    "    else:\n",
    "        tokens = [t for t in doc]\n",
    "    # Remove any empty strings resulting from filtering\n",
    "    return [t for t in tokens if t]\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Loads and preprocesses the FAQ data from the specified JSON file.\"\"\"\n",
    "\n",
    "    # --- DEBUGGING STEP ---\n",
    "    # Print the absolute path to determine the expected file location\n",
    "    absolute_path = os.path.abspath(file_path)\n",
    "    print(f\"Attempting to open file at absolute path: {absolute_path}\")\n",
    "    # -----------------------    \n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Determine the structure: either a list of Q&A pairs or a dict with a 'questions' key\n",
    "        if isinstance(data, dict) and 'questions' in data:\n",
    "            qa_pairs = data['questions']\n",
    "        elif isinstance(data, list):\n",
    "            qa_pairs = data\n",
    "        else:\n",
    "            raise ValueError(\"JSON data structure not recognized (expected list or dict with 'questions').\")\n",
    "\n",
    "        # Extract Questions (Q) and Answers (A)\n",
    "        questions = [item['question'] for item in qa_pairs]\n",
    "        answers = [item['answer'] for item in qa_pairs]\n",
    "        \n",
    "        # Limit to the first 500 pairs for notebook performance\n",
    "        questions = questions[:500]\n",
    "        answers = answers[:500]\n",
    "        \n",
    "        if len(questions) != len(answers) or not questions:\n",
    "            raise ValueError(\"Data extraction failed or corpus is empty.\")\n",
    "\n",
    "        print(f\"Successfully loaded {len(questions)} Q/A pairs from '{file_path}'.\")\n",
    "        return questions, answers\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading local file: {e}.\")\n",
    "        return None\n",
    "\n",
    "# Make sure you downloaded the dataset and is in the following path\n",
    "JSON_FILE_PATH = \"data/Ecommerce_FAQ_Chatbot_dataset.json\"\n",
    "QUESTIONS, ANSWERS = load_data(JSON_FILE_PATH)\n",
    "\n",
    "\n",
    "# --- 2. VECTORIZATION ---\n",
    "\n",
    "# Answers will be the document corpus (D) that we search against\n",
    "DOCUMENT_CORPUS = ANSWERS \n",
    "\n",
    "# Initialize and fit vectorizers on the ANSWER corpus\n",
    "vectorizer_bow = CountVectorizer(tokenizer=spacy_tokenizer, stop_words=None, token_pattern=None)\n",
    "bow_matrix = vectorizer_bow.fit_transform(DOCUMENT_CORPUS)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(tokenizer=spacy_tokenizer, stop_words=None, token_pattern=None)\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(DOCUMENT_CORPUS)\n",
    "\n",
    "print(f\"Corpus Vocabulary Size (TF-IDF): {len(vectorizer_tfidf.get_feature_names_out())}\")\n",
    "\n",
    "\n",
    "# --- 4. PERFORMANCE BENCHMARK FUNCTION ---\n",
    "\n",
    "def calculate_top_1_accuracy(vectorizer, matrix, queries):\n",
    "    \"\"\"\n",
    "    Calculates Top-1 Accuracy: the percentage of times the model correctly \n",
    "    ranks the corresponding answer (at index i) as the top match when querying \n",
    "    with the question (at index i).\n",
    "    \"\"\"\n",
    "    correct_matches = 0\n",
    "    num_queries = len(queries)\n",
    "\n",
    "    # Iterate over every question (Q_i) and treat it as a query\n",
    "    for i, query_text in enumerate(queries):\n",
    "        # 1. Transform the query (Q_i) using the fitted vectorizer\n",
    "        query_vector = vectorizer.transform([query_text])\n",
    "\n",
    "        # 2. Calculate similarity against ALL document vectors (Answers)\n",
    "        similarities = cosine_similarity(query_vector, matrix)[0]\n",
    "        \n",
    "        # 3. Find the index of the best match\n",
    "        best_match_index = np.argmax(similarities)\n",
    "        \n",
    "        # 4. Check if the best match index corresponds to the correct answer index (i)\n",
    "        if best_match_index == i:\n",
    "            correct_matches += 1\n",
    "\n",
    "    return correct_matches / num_queries\n",
    "\n",
    "\n",
    "# --- 5. EXECUTION AND RESULTS ---\n",
    "\n",
    "print(\"\\n--- Running FAQ Retrieval Benchmark ---\")\n",
    "\n",
    "# Calculate BoW accuracy (Questions against Answers)\n",
    "accuracy_bow = calculate_top_1_accuracy(vectorizer_bow, bow_matrix, QUESTIONS)\n",
    "\n",
    "# Calculate TF-IDF accuracy (Questions against Answers)\n",
    "accuracy_tfidf = calculate_top_1_accuracy(vectorizer_tfidf, tfidf_matrix, QUESTIONS)\n",
    "\n",
    "print(f\"\\nTotal Queries Tested: {len(QUESTIONS)}\")\n",
    "print(f\"Top-1 Accuracy (BoW):   {accuracy_bow:.4f} (Raw Frequency Weighting)\")\n",
    "print(f\"Top-1 Accuracy (TF-IDF): {accuracy_tfidf:.4f} (Rarity-Adjusted Weighting)\")\n",
    "\n",
    "if accuracy_tfidf > accuracy_bow:\n",
    "    print(\"\\nConclusion: TF-IDF achieved higher Top-1 accuracy. This is expected in real-world IR tasks because TF-IDF successfully identifies and leverages the discriminatory power of rare terms found between the questions and long answers, filtering out common noise.\")\n",
    "elif accuracy_bow > accuracy_tfidf:\n",
    "    print(\"\\nConclusion: BoW achieved higher Top-1 accuracy. This can happen if the Answers are very long and contain highly repetitive terms that BoW heavily weights, which might be more effective than TF-IDF's penalty on common terms.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Both models performed equally, suggesting the core overlapping terms are frequent and distinctive enough for both weighting schemes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43de4f-5d36-4839-8777-39081bb72d36",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "You can try changing your pre-processing pipeline to see if you get better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56b71f-773f-4da9-90cd-8ba20478eaff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
