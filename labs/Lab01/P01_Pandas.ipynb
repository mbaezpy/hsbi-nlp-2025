{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7cf27b-b501-45bf-8012-80ce85ed2ea7",
   "metadata": {},
   "source": [
    "# Praktikum 1 - Working with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7bda54-aece-46fb-a580-e7713b402e9f",
   "metadata": {},
   "source": [
    "In this lecture we'll go over some basic operations we typically perform with a dataset. In particular, we'll address the following points:\n",
    "- Load and preview dataset\n",
    "- Clean and filter rows\n",
    "- Basic stats and value counts\n",
    "- Grouping and aggregation\n",
    "- Visualizing class balance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e11660-2ec0-49ca-8924-0c57b25b9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb7b90-59b6-4943-9a0a-35a74fd9329e",
   "metadata": {},
   "source": [
    "# 1 Loading datasets\n",
    "\n",
    "### 1.1 Download HF (remote) datasets\n",
    "We can use datasets by using the `.load_dataset()` function from Hugging Face's dataset module. Datasets provides loading scripts to handle the loading of local and remote datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf92e6-6f8d-4d3e-9075-158009433ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcafae-7dd3-42ed-8acc-675ce11239eb",
   "metadata": {},
   "source": [
    "Unfortunately, this node does not have access to the Internet. We can deal with this in different ways, for example with a python script that downloads any given huggingface dataset and it to disc (e.g., download_dataset.py).\n",
    "\n",
    "\n",
    "```python\n",
    "import sys\n",
    "from datasets import load_dataset\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: python download_dataset.py <dataset_name> <output_path>\")\n",
    "        print(\"Example: python download_and_save_dataset.py <hf-user>/<ds-name> /tmp/spam\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    dataset_name = sys.argv[1]\n",
    "    output_path = sys.argv[2]\n",
    "\n",
    "    print(f\"Loading dataset: {dataset_name}\")\n",
    "    ds = load_dataset(dataset_name)\n",
    "\n",
    "    print(f\"Saving dataset to: {output_path}\")\n",
    "    ds.save_to_disk(output_path)\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce10099-d107-4ac9-8b6f-4f4a35990a82",
   "metadata": {},
   "source": [
    "Run the code in the terminal:\n",
    "\n",
    "```bash\n",
    "python download_dataset.py dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset data/sms_spam\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd6561-e430-4714-87ca-ea0b2c4fc384",
   "metadata": {},
   "source": [
    "### 1.2 Loading from disk\n",
    "Now we can load the dataset we downloaded with the `.load_from_disk()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fad946-ff07-400c-a6ac-9410ced27c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hf = load_from_disk(\"data/sms_spam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda922c-283a-4b06-9a81-1e76bb96fbf9",
   "metadata": {},
   "source": [
    "### 1.3 Loading a CSV file\n",
    "You can still use the `datasets` library, or alternatively directly `pandas`. But first let's download a dataset from our terminal (due to the internet connection restriction):\n",
    "\n",
    "```bash\n",
    "curl -L -o data/sms-spam-collection-dataset.zip https://www.kaggle.com/api/v1/datasets/download/uciml/sms-spam-collection-dataset && unzip data/sms-spam-collection-dataset.zip -d data/\n",
    "```\n",
    "\n",
    "This returns a csv file: ``data/spam.csv``\n",
    "\n",
    "#### a. Using HF datasets\n",
    "The datasets library can support different data formats (see https://huggingface.co/learn/llm-course/chapter5/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd22318-b82d-4bfb-8f2b-05cf8838ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_kg = load_dataset(\"csv\", data_files=\"data/spam.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5278b1c-02e7-40eb-b2ca-e9be1946d2c7",
   "metadata": {},
   "source": [
    "#### b. Using Pandas\n",
    "We use `pd.read_csv()` to load our CSV file into a pandas DataFrame. Here we also specify the encoding as 'latin1' to handle special characters properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc30da-4d87-4e42-a0f4-ea2c99767366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg = pd.read_csv(\"data/spam.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e10bc7-547c-4a81-bb85-e6deaf94508b",
   "metadata": {},
   "source": [
    "### 1.4 Datasets vs Pandas\n",
    "\n",
    "\n",
    "`Pandas` is a powerful and intuitive tool for exploratory data analysis and manipulation, especially well-suited for small to medium datasets. On the other hand, `datasets` is tailored for machine learning workflows — offering efficient storage, native support for large datasets, and tight integration with Hugging Face models.\n",
    "\n",
    "\n",
    "| Feature               | `pandas.read_csv()`                     | `datasets.load_dataset(\"csv\")`           |\n",
    "|-----------------------|-----------------------------------------|-------------------------------------------|\n",
    "| Format                | DataFrame (in-memory)                   | Dataset (Arrow-backed, memory-efficient) |\n",
    "| Best for              | EDA, tabular ML tasks                   | NLP workflows, large datasets            |\n",
    "| Integration           | Manual with Transformers                | Native (`map`, `tokenize`, `train_test_split`) |\n",
    "| Performance (large)   | RAM-limited                             | Arrow streaming, efficient for big data  |\n",
    "| Save/Load             | CSV, Pickle                             | `save_to_disk()`, export to CSV          |\n",
    "\n",
    "They are also interoperable:\n",
    "  ```python\n",
    "  df = dataset.to_pandas()           # dataset -> pandas\n",
    "  dataset = Dataset.from_pandas(df)  # pandas -> dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6747cd-a6dd-4497-99f2-471cc9a184ea",
   "metadata": {},
   "source": [
    "# 2 Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578923e1-043b-463d-89ff-f56e71dc82c5",
   "metadata": {},
   "source": [
    "### 2.1 Dataset summary\n",
    "The `.info()` method gives a concise summary of the DataFrame — including column names, non-null counts, and data types.\n",
    "This is useful to check for missing data or inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625d94c-a738-4200-b2b1-4630ddad341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90370b2c-9894-4e8b-a5d0-64db79f9d38d",
   "metadata": {},
   "source": [
    "### 2.2 Previewing the data\n",
    "The `.head()` method shows the first few rows of the DataFrame — useful to get a quick glance at the content and format of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b3318-94d9-4af8-bacc-754da36cd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c551198-c38d-4f4f-88e3-bfde2c5efa10",
   "metadata": {},
   "source": [
    "### 2.3 Dataset dimensions\n",
    "Using `.shape` gives the number of rows and columns in the dataset in the form (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c81fdf-0de0-4ef6-adff-0ec13214184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fef2b-6f27-4a58-b317-67f6912669b7",
   "metadata": {},
   "source": [
    "### 2.4 Columns and indexes\n",
    "`.columns` returns an index of column names in the DataFrame.\n",
    "Helpful to know what fields are available and how they are labeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd710d-7423-45a4-b020-c2331d11f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff47e4a-3d91-4548-875b-33faa6070ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd6fdc-e987-4a1c-9429-54f795c56366",
   "metadata": {},
   "source": [
    "# 3 Accessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace7518-26b1-426e-add7-a30687fa0c82",
   "metadata": {},
   "source": [
    "## 3.1 Accesing values in a column\n",
    "Using `df[\"v1\"]` accesses the `v1` column — this returns a pandas Series containing its values. You can treat it like a list or apply string operations, aggregation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba01c0-3c4c-400e-ab04-fe72f708ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg[\"v1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369206b-6b50-4895-b36a-50a70b3cb693",
   "metadata": {},
   "source": [
    "## 3.2 Slicing Data with `df.loc`\n",
    "We use `df.loc[rows, columns]` to **slice the dataset** by label or condition.\n",
    "\n",
    "- `rows` can be a **range**, a **list of indices**, or a **boolean mask**\n",
    "- `columns` selects specific column(s)\n",
    "\n",
    "Examples:\n",
    "\n",
    "```python\n",
    "df.loc[0]                  # First row (all columns)\n",
    "df.loc[0:4, \"v2\"]        # Rows 0–4, only \"text\" column\n",
    "df.loc[df[\"v1\"] == \"spam\", [\"v1\", \"v2\"]]  # All spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ab226-0c56-481c-b8e1-3c0edd93b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.loc[ : , \"v1\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2562dd-87e4-41f4-be42-37ebd982473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.loc[0:4 , \"v1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56af56-6773-4563-83a5-5c0bfd377fb5",
   "metadata": {},
   "source": [
    "## 3.3 Filtering rows by condition\n",
    "Using .loc[...] with a condition allows us to select rows where v1 == 'spam'.\n",
    "This filters the DataFrame and returns only spam-labeled messages along with their texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f7fa9-3085-447f-a170-b6c9db1ea180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.loc[df_kg[\"v1\"] == \"spam\", [\"v1\", \"v2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d62d5-7ceb-442e-bcc3-f18df4d14a24",
   "metadata": {},
   "source": [
    "Sometimes we need to chain operations. For example, apply more than one filter and even some manipulations in between. We can do this step by step, like below, storing the intermediate steps to perform a filter using a boolean mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f8aa2-8fd0-4330-8362-af6c6c134c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_kg.loc[df_kg[\"v1\"] == \"spam\", [\"v1\", \"v2\"]]\n",
    "df_spam.loc[ df_spam[\"v2\"].str.len() > 150, : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6b7e8-8221-49bb-b867-14b4cb65a0ee",
   "metadata": {},
   "source": [
    "We can also use `lambda` functions inside `.loc`, which are more flexible for **chaining** and **piping** operations.  \n",
    "In this case, the parameter `d` represents the **DataFrame returned by the previous operation**.  \n",
    "This makes the logic more modular and avoids creating intermediate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa465af-a33c-4d8b-9e3e-d91e76a0aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.loc[df_kg[\"v1\"] == \"spam\", [\"v1\", \"v2\"]] \\\n",
    "     .loc[ lambda d : d[\"v2\"].str.len() > 150, : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6853457a-962f-47d3-bf11-fba968227f12",
   "metadata": {},
   "source": [
    "## 3.4 Notes about indexing\n",
    "\n",
    "After filtering row, notice that we do no longer have the 1-N ordering. Above you probably see 2, 8, .. This is because when filtering by rows we are obtaining a view. This means that if we want to obtain the first row, we cannot longer just use the index `0`. Instead, we should get the index of the first element `df.index[0]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c02e46-407a-4c53-9571-e2ecc4cf816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_kg.loc[df_kg[\"v1\"] == \"spam\", [\"v1\", \"v2\"]] \\\n",
    "     .loc[ lambda d : d[\"v2\"].str.len() > 150, : ]\n",
    "\n",
    "# df_x.loc[0]  # Causes a KeyError error\n",
    "df_x.loc[df_x.index[0]] # Obtains the first element of the current view\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4925bb1-9648-4aa6-b8a0-0c5dbfc29692",
   "metadata": {},
   "source": [
    "# 4 Basic Manipulations\n",
    "\n",
    "## 4.1 Views vs Copies\n",
    "When we slice the dataframe and select only columns, `loc` returns a new dataset which is esentially a copy. This means that all operations on this new dataframe do not affect the original one. Let's put this to the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a02f7-0b14-41c9-adbf-67d491f8b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_kg.loc[ :, [\"v1\", \"v2\"]]\n",
    "df_spam[\"v2\"] = \"changed\"\n",
    "print(df_kg[\"v2\"].head())  # Still original values\n",
    "print(df_spam[\"v2\"].head())  # Modified values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc215cc9-831b-4dca-894a-9b1c0af1bd73",
   "metadata": {},
   "source": [
    "Instead, if we filter the dataframe by rows, the operation may raise SettingWithCopyWarning, meaning that pandas **cannot guarantee** that changes won't affect the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a82b31-e534-487a-ac78-d1a0e3199db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_kg.loc[ :, [\"v1\", \"v2\"]]\n",
    "\n",
    "# Filter without copy\n",
    "df_spam_view = df_spam[df_spam[\"v1\"] == \"spam\"]\n",
    "\n",
    "# Modify first row in-place (⚠️ may raise SettingWithCopyWarning)\n",
    "df_spam_view.loc[df_spam_view.index[0], \"v2\"] = \"CHANGED\"\n",
    "\n",
    "# View result\n",
    "print(df_spam_view.head())\n",
    "\n",
    "# Check if original is affected\n",
    "print(\"Original df_kg:\")\n",
    "print(df_spam[df_spam[\"v1\"] == \"spam\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a4f313-d4d5-44b6-8d91-f665985a89c2",
   "metadata": {},
   "source": [
    "Even though it might seem to work fine, it is not given and depends how pandas handles internal optmisations. The best way to safely manipulate the data in this case is creating a copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb45f3f-7986-43d3-adcc-d48b4b2d8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam_view = df_spam[df_spam[\"v1\"] == \"spam\"].copy()\n",
    "df_spam_view.loc[df_spam_view.index[0], \"v2\"] = \"CHANGED\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0390b1-aeb2-4b35-9264-dbd22b6765b3",
   "metadata": {},
   "source": [
    "## 4.2 Working with columns\n",
    "\n",
    "### 4.2.1 Creating columns\n",
    "To **create a new column** in a DataFrame, you simply assign a value or transformation to a column label that doesn’t yet exist. Pandas will automatically create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782f9c7-fd4e-4728-aa14-22e82f4289ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam[\"is_spam\"] = df_spam[\"v1\"] == \"spam\"\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101d1dc-b3b2-423e-b7e1-9d2ec3e7ffd4",
   "metadata": {},
   "source": [
    "### 4.2.2 Dropping columns\n",
    "If a column is no longer needed (e.g., a temporary or duplicate column), you can **remove it** using `.drop(columns=[...])`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a1502-428d-4999-ae9d-a92c63f4b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.drop(columns=[\"v1\"], inplace=True)\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8951b-fa43-4301-8e4d-cb9ad415bbfa",
   "metadata": {},
   "source": [
    "### 4.2.3 Renaming columns\n",
    "The `.rename(columns={...})` method allows you to assign new names to existing columns.\n",
    "This is useful for making column names more meaningful (e.g., renaming 'v2' to 'text')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce63aa8-e0aa-4856-b1f8-1921be26050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.rename(columns={\"v2\" : \"text\" }, inplace = True)\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c33ecc-5c64-48c8-8160-c2f00443efc1",
   "metadata": {},
   "source": [
    "### 4.2.4 Alternatives\n",
    "You could also directly create a clean version of your dataset by selecting and renaming columns in one go. There are two common approaches:\n",
    "\n",
    "1. **Chaining selection + rename**:  \n",
    "   This is explicit and avoids relying on column order.\n",
    "\n",
    "2. **Manual column reassignment**:  \n",
    "   This works well when dynamically assigning new column names.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183130c5-4475-46b0-b5d9-39586cfa92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Chain selection and rename\n",
    "df_clean_1 = df_kg[[\"v1\", \"v2\"]].rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "\n",
    "# Method 2: Assign column names manually\n",
    "df_clean_2 = df_kg[[\"v1\", \"v2\"]].copy()  # Copy is not necessary, but good defensive practice\n",
    "df_clean_2.columns = [\"label\", \"text\"]\n",
    "\n",
    "# Inspect data frame (switch between _1 and _2 to check)\n",
    "df_clean_2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b84341-65fa-47d0-9156-ac411681de27",
   "metadata": {},
   "source": [
    "## 4.3 Working with rows and values\n",
    "\n",
    "### 4.3.1 Replacing values\n",
    "\n",
    "We can replace specific values using using the `replace` function. For example, to replace labels like `\"spam\"` and `\"ham\"` with numeric values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0447d-7b20-467d-b294-a2ae772b3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"label\"] = df[\"label\"].replace({\"spam\": 1, \"ham\": 0})\n",
    "df_spam.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749c02f-bdcf-4746-aa85-dbfc4481b78e",
   "metadata": {},
   "source": [
    "### 4.3.2 Custom transformations using lambda functions\n",
    "We can use `.apply()` with a lambda function to transform rows or values. This can be applied at the column level or at the dataframe level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e19542-c30c-4faa-bbc2-7fd394acbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply it to the values of column \"text\", the function we passed is apply to each value individually\n",
    "df_spam[\"text\"].apply(lambda t : len(t))\n",
    "# df_spam[\"text\"].apply(len).head() # Since len is a function you could pass it directly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36cb5f-764f-4704-b538-974dfec80013",
   "metadata": {},
   "source": [
    "Applying a function at the DataFrame level allows us to use values from **multiple columns** at once.\n",
    "\n",
    "By default, `.apply()` works **column-wise** (`axis=0`).  \n",
    "To process each row individually, we must specify `axis=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292bd442-99e5-465a-911a-189dfad7f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.apply( lambda row : row[\"is_spam\"] and len(row[\"text\"]) > 100, axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6246d7-f349-4070-ba26-566c23033836",
   "metadata": {},
   "source": [
    "### 4.3.2 Sorting rows by a column\n",
    "We can sort the rows in our dataframe with `.sort_values()` by one or more columns. For example, if we want to sort it by lenght of of the text.\n",
    "\n",
    "```python\n",
    "df.sort_values(by=[\"length\", ascending=False, inplace=False)\n",
    "```\n",
    "`by` and `ascending` can receive a string in case of single columns, or an array in case of multiple columns. By default, it creates a new dataset unless `inplace=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776b3cd-76a2-4555-a39f-0924c8b28b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam[\"length\"] = df_spam[\"text\"].apply(lambda t : len(t))\n",
    "\n",
    "# Example with one column\n",
    "df_sorted = df_spam.sort_values(by=\"length\", ascending=False)\n",
    "\n",
    "# Example with multiple columns:\n",
    "#df_sorted = df_spam.sort_values(by=[\"label\", \"length\"], ascending=[True, False]).head()\n",
    "\n",
    "# Inspect sorted dataframe\n",
    "df_sorted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da71c79-6d0f-4b5d-983e-4711b62fbb1f",
   "metadata": {},
   "source": [
    "The idexes from the original dataset are preserved by default (as you can see above). This is to maintain reference i can you want to later join / merge different dataframes or even backtracking. To reindex the dataframe, run `reset_index` with `drop=True` if you don't want the old index to be added as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088501f-1efa-4e02-9a95-ae98b7d3623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "df_sorted\n",
    "\n",
    "# df_sorted.reset_index() # -> this would add a new column \"index\" with the old index\n",
    "\n",
    "# You can chain reset index with sort_values\n",
    "# df_sorted = df_spam.sort_values(by=\"length\", ascending=False).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c3a676-8482-4da7-9387-a6cdaac7a18f",
   "metadata": {},
   "source": [
    "### 4.3.3 Dropping values\n",
    "We can drop values using different methods, as shown in the Table below:\n",
    "\n",
    "| Use Case                          | Method / Code Example                                         | Notes |\n",
    "|----------------------------------|---------------------------------------------------------------|-------|\n",
    "| ❌ Drop row by index              | `df.drop(index=42)`                                           | Drops row with index label `42` |\n",
    "| ❌ Drop multiple rows by index    | `df.drop(index=[0, 3, 5])`                                    | Drops several rows |\n",
    "| ❌ Drop rows with condition       | `df = df[df[\"label\"] != \"spam\"]`                             | Keeps only rows where condition is True |\n",
    "| ❌ Drop rows with missing values  | `df.dropna(subset=[\"text\"])`                                 | Only drops if `\"text\"` is missing |\n",
    "| ❌ Drop duplicates by column      | `df.drop_duplicates(subset=[\"text\"])`                        | Removes repeated messages |\n",
    "| Reset index after dropping     | `df.reset_index(drop=True, inplace=True)`                    | Keeps the index clean |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e10f8-36da-4da0-b75f-fe187071d0b2",
   "metadata": {},
   "source": [
    "When cleaning data, we often need to **remove rows that match certain conditions** — for example, empty texts or unwanted labels. A flexible and common approach in Pandas is to **create a new DataFrame by selecting only the rows we want to keep**. We do this using **Boolean indexing**.\n",
    "How it works:\n",
    "\n",
    "- We define a **condition** that returns a **Boolean Series** — one `True` or `False` for each row.\n",
    "- This Boolean Series must have the **same length as the DataFrame**.\n",
    "- We pass it inside square brackets `df[...]` to filter the rows.\n",
    "- The result is a DataFrame containing only the `True` rows.\n",
    "\n",
    "For example, to remove empty or whitespace-only messages we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030f85f-cd41-4a23-a4e8-5f3c13597739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition: df_spam[\"text\"].str.strip() != \"\"\n",
    "# DataFrame: df_spam\n",
    "\n",
    "df_spam = df_spam[df_spam[\"text\"].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096131d-b5d2-4272-ba3c-df05040dc4ce",
   "metadata": {},
   "source": [
    "# 5 Basic statistics\n",
    "\n",
    "## 5.1 Class distributions \n",
    "Check how many examples are labeled per class. We can have raw **value counts** of proportions (normalized). For example, we want to know the distribution of spam and ham labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03295561-08b9-40bb-bf07-32740269a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam[\"is_spam\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66bfdc-53bf-41fe-9e71-f4c51c3a063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam[\"is_spam\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14464bd2-9bb4-400a-9680-1b7c7484dd1c",
   "metadata": {},
   "source": [
    "We can visualise this with `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc11854-40b5-4548-bcc3-bd61090f9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_spam[\"is_spam\"].value_counts().plot(kind=\"bar\", title=\"Class Distribution\")\n",
    "plt.xlabel(\"Is_Spam?\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdf0d1-8279-4395-be0e-c2e629139668",
   "metadata": {},
   "source": [
    "## 5.2 Descriptive statistics (spread and centrality)\n",
    "The `.describe()` method summarizes numerical columns — including count, mean, std, min, and percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db7d7c-b471-47a2-942b-9bffc55b6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam[\"length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0c371-969c-43ed-82bc-06fcb57da50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam[\"length\"].hist(bins=30)\n",
    "plt.xlabel(\"Message Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Message Lengths\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbddf7-d1bd-4a4f-967c-24e54b6537dc",
   "metadata": {},
   "source": [
    "## 5.3 Unique, duplicate and missing values\n",
    "We can list the unique values with `.unique()` and number of unique values with `.nunique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c46573-6760-4408-b616-72b9ec17f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam[\"text\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dbf65-6c72-4c87-acc7-b6ede5c726a8",
   "metadata": {},
   "source": [
    "### 5.3.2 Duplicates\n",
    "The `.duplicated()` function in Pandas helps identify rows that are repeated in a DataFrame. It returns a Boolean Series where each value is `True` if the row is a duplicate of a **previous** one (based on all or selected columns), and `False` otherwise. By default, it keeps the **first occurrence** and marks subsequent duplicates as `True`, but you can change this behavior using the `keep` parameter (e.g., `\"last\"` or `False` to mark all duplicates). This is useful for spotting and removing repeated messages — a common issue in real-world NLP datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb7134-8c4c-4bd9-ba25-4d5f48ce0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c3d6a-5e1a-4106-950d-ad1fc0214eca",
   "metadata": {},
   "source": [
    "The `.drop_duplicates()` method removes duplicated rows, keeping only the first (by default).\n",
    "You can specify subset to check for duplicates based on specific columns (e.g., \"text\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09ad01-3b31-431e-b7f8-77b135dc80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcfd87-0f44-43ed-98a0-440334b2c094",
   "metadata": {},
   "source": [
    "### 5.3.3 Missing values\n",
    "The `.isna()` method returns a Boolean DataFrame indicating which values are missing (NaN). You can use to spot those rows, count how many there are, and also delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616be40-efbe-4d0a-be70-b5306771c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff3a3e-2420-4e66-8cac-775a0c623e62",
   "metadata": {},
   "source": [
    "### 5.3.4 Group values \n",
    "The `.groupby()` function lets you split your dataset into **groups** based on a column (e.g., labels), and then apply an **aggregation** (like mean, count, or max) to each group. This is useful when you want to compare statistics **between categories** — like spam vs ham messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855009bc-c2cc-4be3-a1f2-f7577a1f61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.groupby(\"is_spam\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e05c7-8a4d-47cb-8f78-b35d517e6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.groupby(\"is_spam\")[\"length\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba585ff-a6ab-42ec-8c4b-b30f9ec9fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.groupby(\"is_spam\")[\"length\"].agg([\"mean\", \"max\", \"min\", \"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3d1cc-0b8c-4963-8b53-1b8a741cceb9",
   "metadata": {},
   "source": [
    "# Additional resources\n",
    "\n",
    "- https://github.com/TirendazAcademy/PANDAS-TUTORIAL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
