{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf628f9d-cc0d-4c76-b269-9ac79ed28fb0",
   "metadata": {},
   "source": [
    "# VL02 - Regular Expression - Basics & Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa729f1-0f7e-4f03-9d09-abbc54db4e8a",
   "metadata": {},
   "source": [
    "A regular expression is a compact mini-language for describing text patterns — good for quick extraction, validation and compact rules, but brittle to variation and obfuscation.\n",
    "\n",
    "\n",
    "\n",
    "# `re` operations — quick reference table \n",
    "\n",
    "| Operation                    |                                     Function | Description                                                                                                                             |                     Return value | One-line example                                                              |\n",
    "| ---------------------------- | -------------------------------------------: | --------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------: | ----------------------------------------------------------------------------- |\n",
    "| Search first match anywhere  |                   `re.search(pattern, text)` | Finds the **first** match in `text`; returns a `Match` object or `None`. Useful to test existence or get span/groups.                   |                `Match` or `None` | `m = re.search(r\"\\bemail\\b\", \"no email here\"); bool(m)`                       |\n",
    "| Match at start only          |                    `re.match(pattern, text)` | Tries to match **only at the start** of the string. (Use `^` with `search` for similar behaviour.)                                      |                `Match` or `None` | `bool(re.match(r\"Hello\", \"Hello world\"))`                                     |\n",
    "| Full-string match            |                `re.fullmatch(pattern, text)` | Returns a match **only if the entire string** fits the pattern. Good for strict validation.                                             |                `Match` or `None` | `bool(re.fullmatch(r\"\\d{4}-\\d{2}-\\d{2}\", \"2025-09-05\"))`                      |\n",
    "| Find all matches (strings)   |                  `re.findall(pattern, text)` | Returns a **list** of all matched substrings (or group-tuples if pattern has groups). Quick extraction.                                 |     `list[str]` or `list[tuple]` | `re.findall(r\"\\b\\w+\\b\", \"one, two 3\")`                                        |\n",
    "| Iterate matches (with spans) |                 `re.finditer(pattern, text)` | Returns an **iterator** of `Match` objects (gives `.group()`, `.span()`, named groups). Memory-friendly for large texts.                |              iterator of `Match` | `for m in re.finditer(r\"\\d+\", \"id42 id7\"): print(m.group(), m.span())`        |\n",
    "| Split by pattern             |                    `re.split(pattern, text)` | Splits `text` using the pattern as delimiter. Useful for flexible tokenization/field splitting.                                         |                      `list[str]` | `re.split(r\"[,\\s]+\", \"a, b,c  d\")`                                            |\n",
    "| Substitute / replace         |                `re.sub(pattern, repl, text)` | Replace matches with `repl` (string or callable). Useful for normalization or masking.                                                  |                            `str` | `re.sub(r\"\\d+\", \"<NUM>\", \"price 12 and 7\")`                                   |\n",
    "| Substitution + count         |               `re.subn(pattern, repl, text)` | Same as `sub` but returns `(new_text, n_subs)` — handy when you need how many replacements happened.                                    |                     `(str, int)` | `re.subn(r\"\\s+\", \" \", \"a   b\")`                                               |\n",
    "| Compile reusable pattern     |             `re.compile(pattern, flags=...)` | Compile a pattern into a `Pattern` object for reuse (faster if used many times). Use `.findall()`, `.search()`, `.sub()` on the object. |                        `Pattern` | `P = re.compile(r\"\\bfree\\b\", re.I); P.findall(\"Free free\")`                   |\n",
    "| Escape literal strings       |                            `re.escape(text)` | Escape user input so it can be used safely in a regex (turns `.` → `\\.` etc.).                                                          |                            `str` | `re.escape(\"a+b.c?\")`                                                         |\n",
    "| Named groups & captures      |              `(?P<name>...)` inside patterns | Capture parts of a match with a **name**; access via `m.group(\"name\")`. Useful for structured extraction.                               |              via `Match.group()` | `m=re.search(r\"(?P<user>[\\w.-]+)@(?P<dom>[\\w.-]+\\.\\w+)\", s); m.group(\"user\")` |\n",
    "| Lookaround (non-consuming)   | `(?=...)`, `(?!...)`, `(?<=...)`, `(?<!...)` | Check context **without** consuming chars (lookahead/lookbehind). Powerful for context-sensitive matches.                               |              used inside pattern | `re.findall(r\"(?<=\\$)\\d+\", \"Price $12\")`                                      |\n",
    "| Verbose / commented patterns |                 `re.X` / `re.VERBOSE` (flag) | Allow whitespace and `#` comments in pattern for readability. Good for complex patterns.                                                | used with `compile` or `findall` | `re.compile(r\"(\\d{2})\\.(\\d{2})\\.(\\d{4})\", re.X)`                              |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24fc459-7b18-49af-ad13-bac4b11412f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# quick comparison\n",
    "print(re.findall(r\"\\d+\", \"Order 42, id 7\"))          # direct one-liner\n",
    "p = re.compile(r\"\\d+\")\n",
    "print(p.findall(\"Order 42, id 7\"))                   # compiled + reused\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db4ea5-d2d6-4fcf-a2f0-a94289f6c300",
   "metadata": {},
   "source": [
    "## Core building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7febcee-a2a7-4505-8d99-7270ebd25700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literals\n",
    "print(re.findall(r\"cat\", \"the cat sat\"))                   # ['cat']\n",
    "\n",
    "# Character classes (range)\n",
    "print(re.findall(r\"[A-Za-z]+\", \"Hello 123 !\"))              # ['Hello']\n",
    "\n",
    "# Negation\n",
    "print(re.findall(r\"[^a-zA-Z]+\", \"abc123!\"))                 # ['123!']\n",
    "\n",
    "# Quantifiers (example: ? optional)\n",
    "print(re.findall(r\"colou?r\", \"color colour\"))               # ['color', 'colour']\n",
    "\n",
    "# Anchors\n",
    "print(re.findall(r\"^[Ss]tart\", \"Start here\\nNot start\"))       # ['Start']\n",
    "print(re.findall(r\"[Ss]tart$\", \"Start here\\nNot start\"))  \n",
    "\n",
    "# Groups & capture (captures alternatives)\n",
    "print(re.findall(r\"(cat|dog)\", \"cat and dog in the yard\"))  # ['cat', 'dog']\n",
    "\n",
    "# Alternation (same effect without capture)\n",
    "print(re.findall(r\"cat|dog\", \"cat dog pig\"))                # ['cat', 'dog']\n",
    "\n",
    "# Greedy vs lazy (lazy example)\n",
    "print(re.findall(r\"<tag>.*?</tag>\", \"<tag>one</tag><tag>two</tag>\"))  # ['<tag>one</tag>', '<tag>two</tag>']\n",
    "\n",
    "# Word boundaries\n",
    "print(re.findall(r\"\\bfree\\b\", \"get free stuff, not freeload\")) # ['free']\n",
    "\n",
    "# Escaping a special char (literal dot)\n",
    "print(re.findall(r\"\\.\", \"a.b c..\"))                         # ['.', '.', '.']\n",
    "\n",
    "# Flags (ignore case)\n",
    "print(re.findall(r\"free\", \"FREE free\", flags=re.I))         # ['FREE', 'free']\n",
    "\n",
    "# Lookarounds (lookbehind example: digits after $)\n",
    "print(re.findall(r\"(?<=\\$)\\d+\", \"Price: $12 and $7\"))       # ['12', '7']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcf34a-b836-4502-a40b-a896ba541323",
   "metadata": {},
   "source": [
    "### Splitting text\n",
    "We can do more than 'matching' / 'fiding' with regular expression. Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7756aef5-3453-4b22-a12c-c05e96319d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['May is nice', 'I may go later', 'Will you join?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['May is nice.', 'I may go later!', 'Will you join?']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"May is nice. I may go later! Will you join?\"\n",
    "\n",
    "# Split *and* keep the delimiter (punctuation) so downstream steps see it\n",
    "parts = re.split(r'[.!?]\\s+', text)\n",
    "\n",
    "print(parts)\n",
    "\n",
    "# This is with the positive lookbehind (?<=) pattern, since it's non consumable. That is, the punctuation won't be part of the \"split\"\n",
    "re.split(r'(?<=[.!?])\\s+', text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066fe8cd-a02e-4790-818e-0332e5aeb94b",
   "metadata": {},
   "source": [
    "### Substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3bce5c7-33d7-412c-9b72-1d83ab0e8f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Win from <MONEY> to <MONEY> dollars!!!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Win from $10 to $100 dollars!!!\"\n",
    "re.sub(r\"\\$\\d+\", \"<MONEY>\", text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659aaa4e-824d-4df8-bf97-7f77ee5a0d46",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Write regular expressions to extract common text signals from short messages: email addresses, URLs, runs of exclamation marks, monetary prices, and occurrences of the word free (including simple obfuscations).\n",
    "\n",
    "2. Then prepare a new array `text_clean` where we substitute the matching email, url, price by the labels 'EMAIL', 'URL\" 'PRICE' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b07bf-f2ce-42d9-89fe-dbb279d1eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_texts = [\n",
    "    \"Get FREE money!!! Visit http://scam.example.com\",\n",
    "    \"Fr33 m0ney!!! Claim your prize now\",\n",
    "    \"Contact us at info@example.com or sales@shop.eu\",\n",
    "    \"Price: $12.40 (special offer)\"\n",
    "]\n",
    "\n",
    "## Write the patter to find each of the following components from the texts\n",
    "patterns = {\n",
    "    \"email\": r\"\",\n",
    "    \"url\":  r\"\",\n",
    "    \"exclamation\": r\"\",\n",
    "    \"price\": r\"\",\n",
    "    \"free\":  r\"\"\n",
    "}\n",
    "\n",
    "# 1) show matches\n",
    "for t in doc_texts:\n",
    "    print(\"TEXT:\", t)\n",
    "    for name, pat in patterns.items():\n",
    "        matches = re.findall(pat, t)\n",
    "        print(f\"  {name}: {matches}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# 2) Substitute email/url/price with labels (keep case/spacing otherwise)\n",
    "\n",
    "# Implement this function\n",
    "def mask_labels(text):\n",
    "    return text\n",
    "\n",
    "for t in texts:\n",
    "    print(\"ORIGINAL:\", t)\n",
    "    print(\"MASKED:  \", mask_labels(t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444732d8-e6ce-40ef-8142-c95a671310d9",
   "metadata": {},
   "source": [
    "## Advanced rules with `Matcher`\n",
    "This snippet demonstrates a compact, production-style rule layer in spaCy: it finds token-level patterns (a normal word or a regex for obfuscation) and punctuation bursts, turns each match into a labeled Span, then filters overlaps so you get the single longest, human-readable matches (e.g., `FREE_WORD`, `EXCLAMATION`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c956b99-47a5-4c20-b488-7c36c3f4a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires: pip install -U spacy && python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import Span\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# token pattern matching the literal \"free\" (case-insensitive) OR tokens that look like obfuscation\n",
    "matcher.add(\"FREE_WORD\", [[{\"LOWER\": \"free\"}], [{\"TEXT\": {\"REGEX\": r\"f[rR][eE3][eE3]\"}}]])\n",
    "\n",
    "# pattern for many punctuation marks (spammy emphasis)\n",
    "matcher.add(\"EXCLAMATION\", [[{\"IS_PUNCT\": True, \"ORTH\": \"!\", \"OP\" : \"+\"}]])\n",
    "\n",
    "for text in doc_texts:\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    # create spans to be able to filter filter each individual match and keep the longest\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    spans = filter_spans(spans)  # optional (keeps the longest match)\n",
    "    print(\"TEXT:\", text)\n",
    "    for s in spans:\n",
    "        print(\" \", s.label_ if s.label_ else \"MATCH\", \"\\t\" ,s.text, [(t.text, t.pos_) for t in s])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a508f2-290a-4529-bf1b-4655a342f7f6",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://www.dataquest.io/cheat-sheet/regular-expressions-cheat-sheet/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
