{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5332c3c0-885e-43d0-93ca-de6a95e1bea5",
   "metadata": {},
   "source": [
    "# VL04 - Text Classification with Naive Bayes\n",
    "In this seminar we demonstrate the full lifecycle of training and evaluating a **Multinomial Naïve Bayes** spam classifier.\n",
    "It connects the ideas from:\n",
    "- **Lab 1 (rule-based spam filter)**:hand-written rules  \n",
    "- **VL03 (text representation)**:Bag-of-Words model  \n",
    "\n",
    "and shows how these come together in a *learned* classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504794e-6ae9-4dc9-b9f5-2142428d2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from datasets import load_from_disk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "except OSError:\n",
    "    print(\"Warning: spaCy model 'en_core_web_sm' not found. Please run 'python -m spacy download en_core_web_sm'\")\n",
    "    # Fallback to a simpler model creation if the standard one fails\n",
    "    nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaf5ad-cf61-4cef-89b7-9998c6c5d42e",
   "metadata": {},
   "source": [
    "## 1. Load and inspect the dataset\n",
    "We use the same small SMS Spam dataset used in the previous labs. If you don't have it, run the following command in your terminal (root of the repository folder).\n",
    "\n",
    "``python scripts/download_dataset.py dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset data/sms_spam``\n",
    "\n",
    "or use directly\n",
    "````python\n",
    "ds = load_dataset(\"dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset\")\n",
    "````\n",
    "if your notebook has access to internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc86c62-3712-43e9-ac95-2e2692fd057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"../../data/sms_spam\")  # columns: ['labels', 'text']\n",
    "df =  ds[\"train\"].to_pandas()\n",
    "\n",
    "df_spam = df[[\"labels\", \"text\"]].copy()\n",
    "df_spam.columns = [\"label\", \"text\"]\n",
    "df_spam.info()\n",
    "\n",
    "# Apparently we have some duplicated rows!\n",
    "df_spam.duplicated(keep=False).sum()\n",
    "df_spam = df_spam.drop_duplicates()\n",
    "\n",
    "df_spam[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58697e93-2bc4-4cb3-af49-dfe3619c03c1",
   "metadata": {},
   "source": [
    "## 2. Split into train/test sets\n",
    "We split the dataset to estimate how well the model generalizes: we train on one partition and evaluate on unseen data; this prevents optimistic results from *testing on the training set*.\n",
    "\n",
    "In practice, we use `train_test_split(..., test_size=0.2, random_state=42, stratify=df_spam[\"label\"])` from sklearn. Here create an 80/20 split **stratified** by the column `label` to preserve the spam/ham ratio in both sets. The `random_state` param is to set the random seed to make the split reproducible.\n",
    "\n",
    "Typically 80/20 is a solid default for small-medium corpora (or / and cross validation). For very large corpora, a 90/10 (or even 95/5) test set is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809678a-21d9-4e70-9d9d-b3cddecb2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_spam[\"text\"], df_spam[\"label\"], test_size=0.2, random_state=42, stratify=df_spam[\"label\"]\n",
    ")\n",
    "\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c6865-c562-453c-bfa3-bb1deeb41a36",
   "metadata": {},
   "source": [
    "## 3. Represent text as Bag-of-Words\n",
    "**Naïve Bayes** relies on frequency-based representations of text, where each word’s occurrence contributes evidence for a class.\n",
    "We use the Bag-of-Words (BoW) model to convert messages into numerical feature vectors—each column represents a word, and each entry its count in a message.\n",
    "\n",
    "As seen in the previous Lab, we can use the `CountVectorizer` for this task. The vectorizer is first fit on the training set to learn the vocabulary and word frequencies, and then the same vocabulary is used to transform the test set, ensuring both datasets share identical feature dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a38eb6-2022-43c1-8ebb-4f2854e49c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(X_train) # fit to the training split\n",
    "X_test_bow  = vectorizer.transform(X_test)      # transform the test split\n",
    "\n",
    "print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e31cb-53f9-4bf6-b876-211e5bac98d3",
   "metadata": {},
   "source": [
    "## 4. Train the Naïve Bayes model\n",
    "The Multinomial Naïve Bayes classifier learns from word frequencies to estimate how strongly each word supports a class (e.g., spam vs. ham).\n",
    "\n",
    "We use the `MultinomialNB` class for this purpose. We can pass many parameters such as:\n",
    "- alpha: value for the laplace smoothing (α = 1 by default)\n",
    "- class_prior: we can override priors `P(c)` (e.g., [0.9, 0.1] ) learned from data, e.g., if you know the % of spam in real life, or want to be more conservative.\n",
    "\n",
    "Then `.fit()` receives the training corpus in bow format `X_train_bow`, and the true labels `y_train`. Here we learn the class prior `P(c)` and conditional word probabilities `P(w | c)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078ba9c-6d26-4037-bf33-f4084170bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=1.0)\n",
    "nb.fit(X_train_bow, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee8a4d-94c9-4fdc-ba25-5b944acb2434",
   "metadata": {},
   "source": [
    "## 5. Evaluate on the test set\n",
    "After training the model, we evaluate its performance on the test set, which contains messages the model has never seen before.\n",
    "We call `.predict()` with the vectorized representation of the test messages. This returns the predicted class for each document — the class with the **highest log-probability** according to the Naïve Bayes model.\n",
    "\n",
    "With both the true labels (`y_test`) and the predicted labels (`y_pred`), we can now measure how well the model generalizes by comparing its predictions to the ground truth.\n",
    "\n",
    "**Remember**: Task matter when interpretting results. What metrics are most important to us when it comes to spam detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf9782-51bc-498b-8167-9573bd245ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(nb, X_test_bow, y_test, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Naïve Bayes Spam Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3919e-9455-4931-8fd8-ef039d4cb0cd",
   "metadata": {},
   "source": [
    "### 5.1 Inspecting class probabilities\n",
    "So far, we used `.predict()` to get only the most likely class for each message — spam or ham.\n",
    "But Naïve Bayes is a probabilistic model, meaning it actually computes a full probability distribution over classes for every document.\n",
    "\n",
    "We can access these values with `.predict_proba()`, which returns a matrix where each row corresponds to a message and each column to a class: `P(class | message)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099f1a5-0674-4513-b59c-c22315e05575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted probabilities for each class\n",
    "y_proba = nb.predict_proba(X_test_bow)\n",
    "\n",
    "# Check the class order\n",
    "print(\"Class order:\", nb.classes_)\n",
    "\n",
    "# Example: show the first 5 rows\n",
    "df_proba = pd.DataFrame(y_proba, columns=nb.classes_)\n",
    "df_proba[\"true_label\"] = y_test.values\n",
    "df_proba[\"message\"] = X_test.values\n",
    "\n",
    "# Reorder columns for readability\n",
    "df_proba = df_proba[[\"message\", \"true_label\", \"ham\", \"spam\"]]\n",
    "\n",
    "# Show first few rows\n",
    "pd.set_option(\"display.max_colwidth\", 100)  # so text isn't truncated\n",
    "df_proba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc960980-2bd8-4b9d-9170-56eb9c8a6e4a",
   "metadata": {},
   "source": [
    "### 5.2 Adjusting the decision threshold\n",
    "By default, `.predict()` labels a message as the class with the highest probability, effectively using a threshold of 0.5 in binary classification.\n",
    "However, for spam detection we may want to be more conservative — for example, labeling a message as spam only if\n",
    "`P(spam | d) >= τ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23114d6-9fb0-4f33-939f-b0401fa133cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom threshold τ\n",
    "tau = 0.6\n",
    "p_spam = y_proba[:, nb.classes_.tolist().index(\"spam\")]\n",
    "y_pred_tau = np.where(p_spam >= tau, \"spam\", \"ham\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_tau, digits=3))\n",
    "\n",
    "# let's compute our confusion matrix with our predictions\n",
    "cm = confusion_matrix(y_test, y_pred_tau, labels=nb.classes_) \n",
    "\n",
    "# we pass the computex matrix to display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=nb.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix — Naïve Bayes (τ ={tau})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97591e02-d557-4ad8-9698-012f9ee2576f",
   "metadata": {},
   "source": [
    "### 5.3 Inspect learned probabilities\n",
    "Which words are most indicative of **spam** or **ham**?\n",
    "\n",
    "After training, the Naïve Bayes model has learned how strongly each word supports one class over the other.\n",
    "For every word w and class c, it stores:\n",
    "- log P(w | c) — how likely the word is under that class\n",
    "- log P(c) — the prior probability of that class\n",
    "\n",
    "When classifying a new message, the model sums these log-probabilities across all words:\n",
    "\n",
    "`log P(c) + ∑ count(w,d) × log P(w | c)`\n",
    "\n",
    "A word is spam-indicative if it occurs much more often in spam than ham. That is:\n",
    "\n",
    "`log P(w | spam) − log P(w | ham) > 0)`\n",
    "\n",
    "and ham-indicative if the opposite is true.\n",
    "\n",
    "By comparing these learned probabilities, we can see which words the model considers most characteristic of spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee4f01-2610-471d-ac09-ba27eda3dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_indicative_features(nb, vectorizer, topk=10, verbose=True):\n",
    "    # 1. Identify class indices (spam = 1, ham = 0)\n",
    "    classes = nb.classes_.tolist()\n",
    "    i_spam  = classes.index(\"spam\")\n",
    "    i_ham   = classes.index(\"ham\")\n",
    "    \n",
    "    # 2. Retrieve the learned log probabilities for each word and class\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    log_pw = nb.feature_log_prob_\n",
    "    \n",
    "    # 3. Compute the log-odds for each feature: spam minus ham\n",
    "    log_odds = log_pw[i_spam] - log_pw[i_ham]\n",
    "    \n",
    "    # 4. Build a small DataFrame for inspection\n",
    "    df_weights = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"logP_w_given_spam\": log_pw[i_spam], # log P(w | spam)\n",
    "        \"logP_w_given_ham\":  log_pw[i_ham],  # log P(w | ham)\n",
    "        \"logodds_spam_minus_ham\": log_odds,  # log P(w | spam) - log P(w | ham)\n",
    "        \"odds_ratio\": np.exp(log_odds)  # x times more likely to be of that class\n",
    "    }).sort_values(\"logodds_spam_minus_ham\", ascending=False)\n",
    "    \n",
    "    # 5. Display the top indicative words for each class\n",
    "\n",
    "    top_spam = df_weights.head(topk)                 # most spam-indicative\n",
    "    top_ham  = df_weights.tail(topk).iloc[::-1]      # most ham-indicative\n",
    "\n",
    "    if (verbose):\n",
    "        print(\"Top spam-indicative features:\")\n",
    "        display(top_spam[[\"feature\", \"logodds_spam_minus_ham\", \"odds_ratio\"]])    \n",
    "        print(\"\\nTop ham-indicative features:\")\n",
    "        display(top_ham[[\"feature\", \"logodds_spam_minus_ham\", \"odds_ratio\"]])\n",
    "    else:    \n",
    "        spam_words = \", \".join(top_spam[\"feature\"].tolist())\n",
    "        ham_words  = \", \".join(top_ham[\"feature\"].tolist())\n",
    "        print(f\"Top spam-indicative words ({topk}):\\n {spam_words}\")\n",
    "        print()\n",
    "        print(f\"Top ham-indicative words  ({topk}):\\n {ham_words}\")\n",
    "        \n",
    "print_indicative_features(nb, vectorizer, topk=15, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971023d5-ddbf-43ab-acca-19cc83e523fc",
   "metadata": {},
   "source": [
    "## 6. Inference on new messages\n",
    "We now apply the model to unseen examples to see how it combines prior + likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea6b21-5133-4c48-9181-e929a47c7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    \"Win a free prize today!\",\n",
    "    \"Lunch meeting tomorrow at noon\",\n",
    "    \"Congratulations!!! Claim your reward now\",\n",
    "]\n",
    "X_samples = vectorizer.transform(samples)\n",
    "preds = nb.predict(X_samples)\n",
    "probs = nb.predict_proba(X_samples)\n",
    "\n",
    "# Find the column index for \"spam\"\n",
    "classes = nb.classes_.tolist()\n",
    "i_spam = classes.index(\"spam\")  # robust way\n",
    "\n",
    "for msg, label, prob in zip(samples, preds, probs):\n",
    "    print(f\"{msg:50s} → {label.upper()}  (P(spam)={prob[i_spam]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391839b5-69e1-4c07-97f7-de3ddb394f7e",
   "metadata": {},
   "source": [
    "## 7. Custom pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194ce36-e02e-4a03-97fb-cf568202f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, html, unicodedata\n",
    "\n",
    "def spacy_tokenizer(text, do_normalise=True):\n",
    "    \"\"\"\n",
    "    Custom tokenizer with numeric normalization.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_space or token.is_stop:\n",
    "            continue\n",
    "\n",
    "        lemma = token.lemma_ if do_normalise else token.text\n",
    "        tokens.append(lemma)\n",
    "\n",
    "    return [t for t in tokens if t]\n",
    "    \n",
    "\n",
    "def run_nb_pipeline(custom_tokenizer, class_prior = None):\n",
    "    \"\"\"Train NB. class_prior = [P(ham), P(spam)] or None to learn from data.\"\"\"\n",
    "    vectorizer = CountVectorizer(tokenizer=custom_tokenizer, stop_words=None, token_pattern=None)\n",
    "    X_train_bow = vectorizer.fit_transform(X_train)\n",
    "    X_test_bow  = vectorizer.transform(X_test)\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())}\")\n",
    "    \n",
    "    nb = MultinomialNB(alpha=1.0, class_prior=class_prior)\n",
    "    nb.fit(X_train_bow, y_train)\n",
    "    \n",
    "    y_pred = nb.predict(X_test_bow)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(nb, X_test_bow, y_test, cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix – Naïve Bayes Spam Classifier with custom pre-processing \")\n",
    "    plt.show()\n",
    "\n",
    "    # We print out the top indicative words\n",
    "    print_indicative_features(nb, vectorizer, topk=300, verbose=False)\n",
    "\n",
    "    return (nb, vectorizer, y_pred)\n",
    "\n",
    "nb_a, vec_a, y_pred_a = run_nb_pipeline(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb21bc2c-be9e-4b8c-b1b0-3705e5d3863b",
   "metadata": {},
   "source": [
    "## 8. Custom features\n",
    "We can also add more than \"word\" features to NB. There are different ways to do so, a simpler one being injecting special tokens into NB. For example, we can have a features such as\n",
    "- `__HAS_EXCLAM__` if the given message has a number of excalamation points !!\n",
    "- `__MANY_CAPS__` if the messages have more than a given number of uppercase words\n",
    "\n",
    "We can also clean our text further by collapsing certain patterns that are spelled differently. For example, we can collapse all variations of \"terms and conditions\", such as \"t&c\", \"ts&cs\" that are featured in the dataset and are currently counted as separate tokens. \n",
    "\n",
    "We also have numbers being counted separately as individual tokens, e.g., '500', '180', so we can characterise numbers, phone numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67b486-930f-400d-83bc-850dcd8b1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_STRONG_RE = re.compile(r\"\"\"(?ix)\n",
    "\\b\n",
    "(\n",
    "  (?:https?://|ftp://)?                                  # optional scheme\n",
    "  (?:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?\\.)+           # subdomain(s)\n",
    "  (?:                                                    # TLD / eTLD\n",
    "      com|org|net|info|biz|edu|gov|mil|io|me|tv|cc|\n",
    "      co|uk|co\\.uk|ac\\.uk|gov\\.uk|au|ca|de|fr|es|it|nl|se|no|fi|pl|in|cn|\n",
    "      us|za|be|ch|at|dk|ru|ie|nz\n",
    "      | [a-z]{2}                                         # generic ccTLD fallback\n",
    "  )\n",
    "  (?:/[^\\s]*)?                                          # optional path\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "EXCLAM_RE = re.compile(r\"!{2,}\")\n",
    "PHONE_RE     = re.compile(r'(?:\\+?\\d[\\s\\-\\(\\)]?){7,}\\d')                   # ~8+ digits total\n",
    "TNC_RE = re.compile(\n",
    "    r'\\b(?:t.?s?\\s*(?:&|and)*\\s*c(?:s|\\'s)?|terms?\\s*(?:&|and)?\\s*conditions?)\\b',\n",
    "    re.I\n",
    ")\n",
    "\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "def pre_normalize(text: str) -> str:\n",
    "    # 1) HTML decode & strip residual tags\n",
    "    t = html.unescape(text)\n",
    "    t = TAG_RE.sub(\" \", t)\n",
    "\n",
    "    # 2) Collapse weird entity leftovers and whitespace\n",
    "    t = re.sub(r\"&(?:amp|nbsp);\", \" \", t, flags=re.I) # annonimized information?\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    #t = unicodedata.normalize('NFKC', t)\n",
    "    return t\n",
    "\n",
    "def replace_signals_in_text(text: str, normalize = True) -> str:\n",
    "    t = pre_normalize(text) if normalize else text\n",
    "\n",
    "    t = TNC_RE.sub(\" __HAS_TNC__ \", t)\n",
    "    t = URL_STRONG_RE.sub(\" __HAS_URL__ \", t)\n",
    "    t = PHONE_RE.sub(\" __HAS_PHONE__ \", t)\n",
    "    t = EXCLAM_RE.sub(\" __HAS_EXCLAM__ \", t)\n",
    "\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def hybrid_tokenizer(raw_text, do_normalise=True, caps_threshold: int = 3):\n",
    "    rewritten = replace_signals_in_text(raw_text, normalize=False)       \n",
    "    doc = nlp(rewritten)\n",
    "\n",
    "    # --- doc-level ALL-CAPS detection (before filtering) ---\n",
    "    caps_count = sum(\n",
    "        1 for tok in doc\n",
    "        if tok.is_alpha and tok.text.isupper() and len(tok.text) >= 2\n",
    "    )\n",
    "\n",
    "    tokens = []\n",
    "    for tok in doc:\n",
    "        if tok.is_punct or tok.is_space or tok.is_stop:\n",
    "            continue\n",
    "\n",
    "        # numeric normalization\n",
    "        if tok.like_num:\n",
    "            tokens.append(\"__IS_DIGIT__\")\n",
    "            continue\n",
    "        if any(ch.isdigit() for ch in tok.text):\n",
    "            tokens.append(\"__HAS_NUM__\")\n",
    "            continue\n",
    "\n",
    "        # preserve placeholders exactly as written ---\n",
    "        if tok.text.startswith(\"__\") and tok.text.endswith(\"__\"):\n",
    "            tokens.append(tok.text)\n",
    "            continue        \n",
    "\n",
    "        lemma = tok.lemma_ if do_normalise else tok.text\n",
    "        tokens.append(lemma)\n",
    "\n",
    "    # append doc-level caps signal once (no duplicates)\n",
    "    if caps_count >= caps_threshold:\n",
    "        tokens.append(\"__MANY_CAPS__\")\n",
    "\n",
    "    \n",
    "    return [t for t in tokens if t]\n",
    "\n",
    "# We inform spacy tokenizer to consider the different placeholders as complete tokens (otherwise might get splitted)\n",
    "PLACEHOLDERS = [\n",
    "    \"__HAS_TNC__\", \"__HAS_URL__\", \"__HAS_EXCLAM__\", \n",
    "    \"__HAS_PHONE__\", \"__MANY_CAPS__\"\n",
    "]\n",
    "\n",
    "for ph in PLACEHOLDERS:\n",
    "    nlp.tokenizer.add_special_case(ph, [{ORTH: ph}])\n",
    "\n",
    "\n",
    "# Let's run the pipeline (function from before) with our new custom tokenizer with advanced processing and signals\n",
    "nb_b, vec_b, y_pred_b = run_nb_pipeline(hybrid_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfc75a-ef17-4546-82b5-136339f3674d",
   "metadata": {},
   "source": [
    "### Inspect errors\n",
    "The following helper functions let you analyze misclassified messages and understand why the model made a certain prediction. Qualitatively analysing the output of your model is a good way of understanding if there are patters of errors that can be addressed.\n",
    "\n",
    "Use `.preview_errors_explained()` to scan all test samples, providing the true label you want to explore. Then it selects the messages that were misclassified and displays a table with:\n",
    "\t•\tthe true and predicted labels,\n",
    "\t•\tthe model’s estimated probability of spam,\n",
    "\t•\tthe top positive and negative evidence (words), and\n",
    "\t•\tthe original text for context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294a957-697e-4c42-b06f-700a3454f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def explain_message(nb, vectorizer, text, top_k=10, pos_label=\"spam\"):\n",
    "    \"\"\"\n",
    "    Return a dict with posterior, log-odds breakdown, and top contributing features.\n",
    "    Works for MultinomialNB with a CountVectorizer/TF pipeline.\n",
    "    \"\"\"\n",
    "    # Map class indices\n",
    "    classes = list(nb.classes_)\n",
    "    i_pos = classes.index(pos_label)\n",
    "    i_neg = 1 - i_pos  # binary assumption\n",
    "\n",
    "    # Vectorize this text\n",
    "    X = vectorizer.transform([text])               # shape (1, V)\n",
    "    x = X.tocsr()                                  # ensure CSR\n",
    "    idx = x.indices\n",
    "    vals = x.data\n",
    "\n",
    "    # Feature names and per-class log P(w|c)\n",
    "    feat = vectorizer.get_feature_names_out()\n",
    "    log_pw_pos = nb.feature_log_prob_[i_pos]       # shape (V,)\n",
    "    log_pw_neg = nb.feature_log_prob_[i_neg]\n",
    "\n",
    "    # Class-log-priors\n",
    "    lp_pos = nb.class_log_prior_[i_pos]\n",
    "    lp_neg = nb.class_log_prior_[i_neg]\n",
    "    prior_diff = lp_pos - lp_neg                   # log-odds prior term\n",
    "\n",
    "    # Per-feature log-odds weights (spam minus ham)\n",
    "    w = log_pw_pos - log_pw_neg                    # shape (V,)\n",
    "\n",
    "    # Contributions for active features: w_i * count_i\n",
    "    contrib_vals = w[idx] * vals\n",
    "    contrib_pairs = list(zip(feat[idx], contrib_vals))\n",
    "\n",
    "    # Split into pro-spam (positive) and pro-ham (negative) evidence\n",
    "    pos_contrib = sorted([(t, c) for t, c in contrib_pairs if c > 0], key=lambda z: -z[1])[:top_k]\n",
    "    neg_contrib = sorted([(t, c) for t, c in contrib_pairs if c < 0], key=lambda z: z[1])[:top_k]\n",
    "\n",
    "    # Total log-odds and posterior\n",
    "    log_odds = prior_diff + contrib_vals.sum()\n",
    "    # convert log-odds to probability\n",
    "    p_pos = 1.0 / (1.0 + np.exp(-log_odds))\n",
    "\n",
    "    return {\n",
    "        \"p_spam\": float(p_pos) if pos_label == \"spam\" else 1.0 - float(p_pos),\n",
    "        \"log_odds\": float(log_odds),\n",
    "        \"prior_log_odds\": float(prior_diff),\n",
    "        \"sum_feature_contrib\": float(contrib_vals.sum()),\n",
    "        \"top_pos\": pos_contrib,    # [(feature, +weight), ...]\n",
    "        \"top_neg\": neg_contrib,    # [(feature, -weight), ...]\n",
    "        \"active_count\": int(len(idx)),\n",
    "    }\n",
    "\n",
    "def preview_errors_explained(X_test, y_test, y_pred, nb, vectorizer,\n",
    "                             true_label=\"ham\", pos_label=\"spam\", top_k=5):\n",
    "    # align predictions to y_test index\n",
    "    y_pred_s = pd.Series(y_pred, index=y_test.index)\n",
    "    err_mask = (y_test == true_label) & (y_pred_s != true_label)\n",
    "    err_idx = y_test.index[err_mask]\n",
    "\n",
    "    rows = []\n",
    "    for i in err_idx:\n",
    "        # Handle both DataFrame-with-text-column and plain Series cases\n",
    "        text = X_test.loc[i, \"text\"] if hasattr(X_test, \"columns\") and \"text\" in X_test.columns else X_test.loc[i]\n",
    "        exp = explain_message(nb, vectorizer, text, top_k=top_k, pos_label=pos_label)\n",
    "        rows.append({\n",
    "            \"index\": i,\n",
    "            \"true\": y_test.loc[i],\n",
    "            \"pred\": y_pred_s.loc[i],\n",
    "            \"p_spam\": round(exp[\"p_spam\"], 6),\n",
    "            \"log_odds\": round(exp[\"log_odds\"], 6),\n",
    "            \"prior_log_odds\": round(exp[\"prior_log_odds\"], 6),\n",
    "            \"sum_feature_contrib\": round(exp[\"sum_feature_contrib\"], 6),\n",
    "            \"top_pos\": exp[\"top_pos\"],\n",
    "            \"top_neg\": exp[\"top_neg\"],\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No errors for this selection.\")\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"index\",\"true\",\"pred\",\"p_spam\",\"log_odds\",\n",
    "            \"prior_log_odds\",\"sum_feature_contrib\",\"top_pos\",\"top_neg\",\"text\"\n",
    "        ])\n",
    "\n",
    "    df_exp = pd.DataFrame(rows).sort_values(\"p_spam\", ascending=False)\n",
    "\n",
    "    with pd.option_context('display.max_colwidth', None, 'display.width', 200):\n",
    "        display(df_exp[[\"index\",\"true\",\"pred\",\"p_spam\",\"log_odds\",\"top_pos\",\"top_neg\",\"text\"]])\n",
    "\n",
    "    return df_exp\n",
    "\n",
    "print(\"— Errors with simple processing —\")\n",
    "df_err_A = preview_errors_explained(X_test, y_test, y_pred_a, nb_a, vec_a, true_label=\"ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598cef6-58a0-4b43-a6dc-837ed7ca5418",
   "metadata": {},
   "source": [
    "## 9. Discussion\n",
    "- How does this differ from the **rule-based** filter?  Go back to your implementation and compare performance.\n",
    "- What is the effect of normalising (pre-processing) the text? Try normalising, not normalising and reflect on the results.\n",
    "- Reflect on the performance of the model, and engineered features. What do we gain and lose with your implementation of more advanced pre-processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3c01b-8ac4-459d-9f6d-df1a520cf2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
